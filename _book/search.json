[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análise e Modelagem Classificatória de Dados de Cancer de Mama",
    "section": "",
    "text": "Testes Assintóticos\nO câncer de mama é uma doença complexa e de grande impacto na saúde, afetando milhões de mulheres e alguns homens em todo o mundo. A análise estatística e a modelagem desempenham um papel fundamental no estudo dessa doença, permitindo compreender seus fatores de risco, padrões de ocorrência e desenvolver estratégias eficazes de prevenção e tratamento personalizadas. Neste trabalho, exploraremos a importância da análise estatística na pesquisa sobre câncer de mama, abordando diferentes aspectos desse processo, como a análise de dados epidemiológicos e genéticos, a modelagem para previsão de riscos e o uso de técnicas avançadas para identificar subtipos moleculares."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Câncer de Mama: uma rápida contextualização.",
    "section": "",
    "text": "O câncer de mama é uma doença maligna que se origina no tecido mamário. É o tipo de câncer mais comum entre as mulheres em todo o mundo e também pode afetar os homens, embora seja menos frequente. Caracteriza-se pelo crescimento anormal e descontrolado das células mamárias, formando um tumor que pode se espalhar para outras partes do corpo.\n\nExistem diversos fatores de risco associados ao câncer de mama, como idade avançada, histórico familiar da doença, mutações genéticas, exposição a hormônios, obesidade, consumo excessivo de álcool, entre outros. A detecção precoce é fundamental para o sucesso do tratamento, pois permite o diagnóstico em estágios iniciais, quando as chances de cura são maiores.\nA análise"
  },
  {
    "objectID": "exploratory.html",
    "href": "exploratory.html",
    "title": "2  Carregamento dos dados",
    "section": "",
    "text": "O seguinte capítulo tem como objetivo realizar uma análise exploratória nos dados. Para isso iremos seguir o seguinte esquema:\n\nOs dados utilizados nesse trabalho foram retirados do Kaggle e se tratam de valores estimados a partir de uma imagem digitalizada de um aspirado com agulha fina (PAAF) de uma massa mamária com tumor. Assim, os dados descrevem características dos núcleos celulares presentes nas imagens.\nCarregamento dos dados:\n\n\nRows: 568\nColumns: 33\n$ id                      <dbl> 842302, 842517, 84300903, 84348301, 84358402, ~\n$ diagnosis               <fct> M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M~\n$ radius_mean             <dbl> 17.990, 20.570, 19.690, 11.420, 20.290, 12.450~\n$ texture_mean            <dbl> 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.9~\n$ perimeter_mean          <dbl> 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, ~\n$ area_mean               <dbl> 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, ~\n$ smoothness_mean         <dbl> 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0~\n$ compactness_mean        <dbl> 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0~\n$ concavity_mean          <dbl> 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0~\n$ `concave points_mean`   <dbl> 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0~\n$ symmetry_mean           <dbl> 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087~\n$ fractal_dimension_mean  <dbl> 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0~\n$ radius_se               <dbl> 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345~\n$ texture_se              <dbl> 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902~\n$ perimeter_se            <dbl> 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.18~\n$ area_se                 <dbl> 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.~\n$ smoothness_se           <dbl> 0.006399, 0.005225, 0.006150, 0.009110, 0.0114~\n$ compactness_se          <dbl> 0.049040, 0.013080, 0.040060, 0.074580, 0.0246~\n$ concavity_se            <dbl> 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0~\n$ `concave points_se`     <dbl> 0.015870, 0.013400, 0.020580, 0.018670, 0.0188~\n$ symmetry_se             <dbl> 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0~\n$ fractal_dimension_se    <dbl> 0.006193, 0.003532, 0.004571, 0.009208, 0.0051~\n$ radius_worst            <dbl> 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.8~\n$ texture_worst           <dbl> 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.6~\n$ perimeter_worst         <dbl> 184.60, 158.80, 152.50, 98.87, 152.20, 103.40,~\n$ area_worst              <dbl> 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, ~\n$ smoothness_worst        <dbl> 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791~\n$ compactness_worst       <dbl> 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249~\n$ concavity_worst         <dbl> 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0~\n$ `concave points_worst`  <dbl> 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0~\n$ symmetry_worst          <dbl> 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985~\n$ fractal_dimension_worst <dbl> 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0~\n$ ...33                   <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~\n\n\nNota-se que o conjunto de dados possui 568 observações com 33 variaveis\n\ndata_cancer |> visdat::vis_miss()\n\n\n\n\nA partir do gráfico de valores faltantes, nota-se que apenas uma coluna possui NAs, assim ela foi do conjunto de dados (variavel não apresentava nenhum valor e provalvelmente é resquício de um erro no upload dos dados por parte UCI Machine Learning Repositor)\n\ndata_cancer = data_cancer|>\n  dplyr::select(-'...33' )\n\n\ndata_cancer |> head()\n\n# A tibble: 6 x 32\n        id diagnosis radius_mean texture_mean perimeter_mean area_mean\n     <dbl> <fct>           <dbl>        <dbl>          <dbl>     <dbl>\n1   842302 M                18.0         10.4          123.      1001 \n2   842517 M                20.6         17.8          133.      1326 \n3 84300903 M                19.7         21.2          130       1203 \n4 84348301 M                11.4         20.4           77.6      386.\n5 84358402 M                20.3         14.3          135.      1297 \n6   843786 M                12.4         15.7           82.6      477.\n# i 26 more variables: smoothness_mean <dbl>, compactness_mean <dbl>,\n#   concavity_mean <dbl>, `concave points_mean` <dbl>, symmetry_mean <dbl>,\n#   fractal_dimension_mean <dbl>, radius_se <dbl>, texture_se <dbl>,\n#   perimeter_se <dbl>, area_se <dbl>, smoothness_se <dbl>,\n#   compactness_se <dbl>, concavity_se <dbl>, `concave points_se` <dbl>,\n#   symmetry_se <dbl>, fractal_dimension_se <dbl>, radius_worst <dbl>,\n#   texture_worst <dbl>, perimeter_worst <dbl>, area_worst <dbl>, ...\n\n\nAs 5 primeiras linhas do conjunto de dados mostram que das 32 variáveis remanescentes, 30 são numericas, 1 categórica e a restante representa um ID do paciente analisado. Os modelos desenvolvidos nesse trabalho buscam classificar o diagnóstico do paciente (tumor maligno ou benigno) com base nas variáveis numéricas. Assim é importantíssima a análise de tais variáveis, estudando valores de correlação, aderência e significância\n\n3 Análise e interpretação das variaveis\n\n# ggcorrplot::"
  },
  {
    "objectID": "exploratory.html#carregamento-dos-dados",
    "href": "exploratory.html#carregamento-dos-dados",
    "title": "2  Análise exploratória de Dados",
    "section": "2.1 Carregamento dos dados",
    "text": "2.1 Carregamento dos dados\nOs dados utilizados nesse trabalho foram retirados do Kaggle e se tratam de valores estimados a partir de uma imagem digitalizada de um aspirado com agulha fina (PAAF) de uma massa mamária com tumor. Assim, os dados descrevem características dos núcleos celulares presentes nas imagens.\nCarregamento dos dados:\n\n\nRows: 568\nColumns: 33\n$ id                      <dbl> 842302, 842517, 84300903, 84348301, 84358402, ~\n$ diagnosis               <fct> M, M, M, M, M, M, M, M, M, M, M, M, M, M, M, M~\n$ radius_mean             <dbl> 17.990, 20.570, 19.690, 11.420, 20.290, 12.450~\n$ texture_mean            <dbl> 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.9~\n$ perimeter_mean          <dbl> 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, ~\n$ area_mean               <dbl> 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, ~\n$ smoothness_mean         <dbl> 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0~\n$ compactness_mean        <dbl> 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0~\n$ concavity_mean          <dbl> 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0~\n$ `concave points_mean`   <dbl> 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0~\n$ symmetry_mean           <dbl> 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087~\n$ fractal_dimension_mean  <dbl> 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0~\n$ radius_se               <dbl> 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345~\n$ texture_se              <dbl> 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902~\n$ perimeter_se            <dbl> 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.18~\n$ area_se                 <dbl> 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.~\n$ smoothness_se           <dbl> 0.006399, 0.005225, 0.006150, 0.009110, 0.0114~\n$ compactness_se          <dbl> 0.049040, 0.013080, 0.040060, 0.074580, 0.0246~\n$ concavity_se            <dbl> 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0~\n$ `concave points_se`     <dbl> 0.015870, 0.013400, 0.020580, 0.018670, 0.0188~\n$ symmetry_se             <dbl> 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0~\n$ fractal_dimension_se    <dbl> 0.006193, 0.003532, 0.004571, 0.009208, 0.0051~\n$ radius_worst            <dbl> 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.8~\n$ texture_worst           <dbl> 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.6~\n$ perimeter_worst         <dbl> 184.60, 158.80, 152.50, 98.87, 152.20, 103.40,~\n$ area_worst              <dbl> 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, ~\n$ smoothness_worst        <dbl> 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791~\n$ compactness_worst       <dbl> 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249~\n$ concavity_worst         <dbl> 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0~\n$ `concave points_worst`  <dbl> 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0~\n$ symmetry_worst          <dbl> 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985~\n$ fractal_dimension_worst <dbl> 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0~\n$ ...33                   <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~\n\n\nNota-se que o conjunto de dados possui 568 observações com 33 variaveis\n\ndata_cancer |> visdat::vis_miss()\n\n\n\n\nA partir do gráfico de valores faltantes, nota-se que apenas uma coluna possui NAs, assim ela foi removida do conjunto de dados (variavel não apresentava nenhum valor e provalvelmente é resquício de um erro no upload dos dados por parte UCI Machine Learning Repositor)\n\ndata_cancer = data_cancer|>\n  dplyr::select(-'...33' )\n\n\ndata_cancer |> head()\n\n# A tibble: 6 x 32\n        id diagnosis radius_mean texture_mean perimeter_mean area_mean\n     <dbl> <fct>           <dbl>        <dbl>          <dbl>     <dbl>\n1   842302 M                18.0         10.4          123.      1001 \n2   842517 M                20.6         17.8          133.      1326 \n3 84300903 M                19.7         21.2          130       1203 \n4 84348301 M                11.4         20.4           77.6      386.\n5 84358402 M                20.3         14.3          135.      1297 \n6   843786 M                12.4         15.7           82.6      477.\n# i 26 more variables: smoothness_mean <dbl>, compactness_mean <dbl>,\n#   concavity_mean <dbl>, `concave points_mean` <dbl>, symmetry_mean <dbl>,\n#   fractal_dimension_mean <dbl>, radius_se <dbl>, texture_se <dbl>,\n#   perimeter_se <dbl>, area_se <dbl>, smoothness_se <dbl>,\n#   compactness_se <dbl>, concavity_se <dbl>, `concave points_se` <dbl>,\n#   symmetry_se <dbl>, fractal_dimension_se <dbl>, radius_worst <dbl>,\n#   texture_worst <dbl>, perimeter_worst <dbl>, area_worst <dbl>, ...\n\n\nAs 5 primeiras linhas do conjunto de dados mostram que das 32 variáveis remanescentes, 30 são numericas, 1 categórica e a restante representa um ID do paciente analisado. Os modelos desenvolvidos nesse trabalho buscam classificar o diagnóstico do paciente (tumor maligno ou benigno) com base nas variáveis numéricas. Assim é importantíssima a análise de tais variáveis, estudando valores de correlação, aderência e significância\nUm estudo de simulação, assim como a documentação dos dados indica que não há falta de informação ao se trabalhar com a colunas numericas **_mean**, assim\n\ndata_cancer = data_cancer |>\n  dplyr::select(id, diagnosis , dplyr::contains('_mean'))\n\nPara o estudo, há a necessidade de verificação de desbalanceamento do conjunto de dados. Tal verificcação foi feita em cima de análise gráfica, de proporções de cada grupo\n\nprop_df = data_cancer |>\n  dplyr::reframe(prop_B = mean(diagnosis == 'B'), prop_M = mean(diagnosis == 'M')) |>\n  tidyr::pivot_longer(c(prop_B, prop_M))\n\ndata_cancer |> \n  ggplot2::ggplot(ggplot2::aes(x = diagnosis, fill = diagnosis)) +\n  ggplot2::geom_bar() +\n  ggplot2::theme_minimal() +\n  ggthemes::scale_fill_colorblind()\n\n\n\n\nAlem da visualização gráfica, foi utilizado o Coeficiente de Entropia de Shannon, que vai de 0 a 1, onde 0 indica dados totalmente desbalanceados (proporção \\(0\\%\\) e \\(100\\%\\)) e 1 balanceamento completo (proporção \\(50\\%\\) e \\(50\\%\\))\n\nDescTools::Entropy(data_cancer$diagnosis |> table())\n\n[1] 0.953127\n\n\nO Coeficiente calculado foi de: \\(0.953127\\)\nAssim, a partir do grafico de barras, proporções de cada grupo e teste de Entropia de Shannon, não há evidencias para um desbalanceadmento significativo no conjunto de dados utilizados\nO próximo tópico busca tal objetivo .Antes porém, buscando diminuir o vies amostral, o conjunto de dados será divido em treino e teste, com proporção \\(80\\% \\ e \\ 20\\%\\) @, o metodo de divisão utilizado será de amostragem estratificada simples, tal método foi escolhido para evitar desbalanceamento de diagnosticos malignos e benignos nos conjuntos de treino e teste. Portanto, toda a análise e modelagem realizada nos próximos topicos foi em cima do conjunto de dados de teste, ao final da etapa de modelagem foi realizado o ultimo ajuste dos modelos, onde é utilizado o conjunto total dos dados\n\nset.seed(607) #Fixando semente para reprodução dos resultados \ndata_cancer_split = rsample::initial_split(data_cancer, prop = 0.80, strata = diagnosis)\ndata_cancer_train = rsample::training(data_cancer_split)\ndata_cancer_test = rsample::testing(data_cancer_split)"
  },
  {
    "objectID": "exploratory.html#análise-e-interpretação-das-variaveis",
    "href": "exploratory.html#análise-e-interpretação-das-variaveis",
    "title": "2  Análise exploratória de Dados",
    "section": "2.2 Análise e interpretação das variaveis",
    "text": "2.2 Análise e interpretação das variaveis\n\nhist_vars_cancer = apply(data_cancer_train[,3:12], 2, \n      function(vars_){\n          data_cancer_train |>\n          ggplot2::ggplot(ggplot2::aes(x = vars_, color = diagnosis)) +\n          ggplot2::geom_histogram(ggplot2::aes(y = ggplot2::after_stat(density))) +\n          ggthemes::scale_colour_colorblind()\n\n})\n\ndo.call(gridExtra::grid.arrange, hist_vars_cancer)\n\n\n\n\nTeste de aderencia de distribuições para variaveis dividias por grupo:\n\nB = data_cancer_train |>\n      dplyr::filter(diagnosis == 'B') \n\nM = data_cancer_train |>\n      dplyr::filter(diagnosis == 'M') \n\ngrip_test = sapply(3:12, function(i){\n  dist1 = B[,i] |> dplyr::pull()\n  dist2 = M[,i] |> dplyr::pull()\n  ks = ks.test(dist1, dist2)\n  cr = cramer::cramer.test(dist1, dist2)\n  \n  return(c(ks$p.value, cr$p.value))\n})"
  },
  {
    "objectID": "exploratory.html#redução-de-dimensionalidade",
    "href": "exploratory.html#redução-de-dimensionalidade",
    "title": "2  Análise exploratória de Dados",
    "section": "2.3 Redução de dimensionalidade",
    "text": "2.3 Redução de dimensionalidade\nDados do mundo real, como sinais de fala, fotografias digitais ou varreduras de fMRI, geralmente têm alta dimensionalidade. Para lidar adequadamente com os dados do mundo real, dimensionalidade precisa ser reduzida. Redução de dimensionalidade é a transformação de dados de alta dimensão em uma representação significativa de dimensionalidade reduzida. Idealmente, a representação reduzida deve ter uma dimensionalidade que corresponde à dimensionalidade intrínseca dos dados (Van Der Maaten et al. 2009)\n\n2.3.1 Análise de Componentes Principais\nAnálise de Componentes Principais (PCA) constroi uma representação de baixa dimensão dos dados que descreve o máximo possível da variância dos dados.\nA técnica se baseia no cálculo de autovalores e autovetores, buscando assim associção lineares entre as variáveis.\n\npr_cancer = data_cancer_train |>\n  dplyr::select(dplyr::contains('_mean')) |> \n  princomp() \n\n\npr_cancer |> factoextra::fviz_eig()\n\n\n\n\nObservando o gráfico da variabilidade captada por cada componente, viu-se que a primeira dimensão captou grande parte dessa variabilidade e assim, trabalhou-se apenas com uma dimensão na análise dos dados via PCA\nBuscando visualizar quanto cada variável contribui na primeira componente construiu-se o seguinte gráfico\n\npr_cancer |> factoextra::fviz_contrib(choice = \"var\", axes = c(1))\n\n\n\n\n\n\n2.3.2 Análise Fatorial\n\nfa_ml_cancer = data_cancer_train |>\n                dplyr::select(dplyr::contains('_mean')) |>\n  psych::fa(nfactors = 2, rotate = 'varimax', fm = 'ml') \n\nfa_ml_cancer |> psych::fa.diagram()\n\n\n\nfa_ml_cancer$scores |>\n  as.data.frame() |>\n  dplyr::mutate(diagnosis = data_cancer_train$diagnosis) |>\n  ggplot2::ggplot(ggplot2::aes(ML1, ML2, col = diagnosis)) +\n  ggplot2::geom_point(size = 2) +\n  ggplot2::labs(title = 'Redução via Verossimilhança') +\n  ggthemes::scale_colour_colorblind()\n\n\n\n\n\n\n\n\nVan Der Maaten, Laurens, Eric O Postma, H Jaap van den Herik, et al. 2009. “Dimensionality Reduction: A Comparative Review.” Journal of Machine Learning Research 10 (66-71): 13."
  },
  {
    "objectID": "models.html#análise-de-discriminante",
    "href": "models.html#análise-de-discriminante",
    "title": "3  Modelos de Classificação",
    "section": "3.1 Análise de Discriminante",
    "text": "3.1 Análise de Discriminante\nO objetivo da análise discriminante é encontrar uma função discriminante que maximize a separação entre os grupos, levando em consideração a estrutura das variáveis preditoras.\nDado o contexto do problema estudado, a função discriminante estimada foi aquela que maximizou a separação entre os grupos de pessoas com tumor benigno e maligno.\n\n3.1.1 Análise via Discriminante Linear\n\nlibrary(discrim)\n\n\nlda_spec = discrim_linear() |>\n  set_mode('classification') |>\n  set_engine('MASS')\n\nlda_fit = wf |>\n  add_model(lda_spec) |>\n  fit(data = data_cancer_train)\n\n\nlda_metrics = lda_fit |> \n  fit_resamples(cross_folds,\n    metrics = metric_set(accuracy, roc_auc, sens, j_index, specificity),\n    control = control_resamples(save_pred = TRUE)) |>\n  collect_metrics() |>\n  mutate(lower_bound = mean - 1.96*std_err, upper_bound = mean + 1.96*std_err)\n\n\n\n3.1.2 Análise via Discriminante Quadrático\n\ncov_diagnosis = list('B','M') |>\n  map(~data_cancer_train |>\n        filter(diagnosis == .) |>\n        dplyr::select(-'id', -'diagnosis') |>\n        cov())\n\ncov_diagnosis[[1]] - cov_diagnosis[[2]]\n\n                         radius_mean  texture_mean perimeter_mean     area_mean\nradius_mean            -7.047364e+00 -1.389242e+00  -4.850028e+01 -9.276406e+02\ntexture_mean           -1.389242e+00  1.637076e+00  -1.030373e+01 -1.508280e+02\nperimeter_mean         -4.850028e+01 -1.030373e+01  -3.373446e+02 -6.368862e+03\narea_mean              -9.276406e+02 -1.508280e+02  -6.368862e+03 -1.180810e+05\nsmoothness_mean        -6.837970e-04 -8.432898e-03  -1.614651e-02 -7.633860e-02\ncompactness_mean       -2.375424e-02 -2.244713e-02  -2.376794e-01 -2.931297e+00\nconcavity_mean         -1.144228e-01 -3.649685e-02  -8.730480e-01 -1.376004e+01\nconcave points_mean    -6.235187e-02 -1.567726e-02  -4.599717e-01 -7.734859e+00\nsymmetry_mean          -2.133496e-03 -6.745364e-04  -4.386929e-02  1.459941e-01\nfractal_dimension_mean  3.631289e-03 -2.261630e-03   1.793601e-02  6.161046e-01\n                       smoothness_mean compactness_mean concavity_mean\nradius_mean              -6.837970e-04    -0.0237542352  -1.144228e-01\ntexture_mean             -8.432898e-03    -0.0224471327  -3.649685e-02\nperimeter_mean           -1.614651e-02    -0.2376793784  -8.730480e-01\narea_mean                -7.633860e-02    -2.9312972497  -1.376004e+01\nsmoothness_mean           1.874729e-05    -0.0002164962  -4.956260e-04\ncompactness_mean         -2.164962e-04    -0.0018040810  -2.365093e-03\nconcavity_mean           -4.956260e-04    -0.0023650930  -3.764299e-03\nconcave points_mean      -1.490658e-04    -0.0009363516  -1.880670e-03\nsymmetry_mean            -6.661414e-05    -0.0007719450  -8.666418e-04\nfractal_dimension_mean   -2.305303e-05    -0.0001488891  -1.000764e-04\n                       concave points_mean symmetry_mean fractal_dimension_mean\nradius_mean                  -6.235187e-02 -2.133496e-03           3.631289e-03\ntexture_mean                 -1.567726e-02 -6.745364e-04          -2.261630e-03\nperimeter_mean               -4.599717e-01 -4.386929e-02           1.793601e-02\narea_mean                    -7.734859e+00  1.459941e-01           6.161046e-01\nsmoothness_mean              -1.490658e-04 -6.661414e-05          -2.305303e-05\ncompactness_mean             -9.363516e-04 -7.719450e-04          -1.488891e-04\nconcavity_mean               -1.880670e-03 -8.666418e-04          -1.000764e-04\nconcave points_mean          -9.297818e-04 -3.354815e-04          -3.866346e-05\nsymmetry_mean                -3.354815e-04 -2.071237e-04          -6.902961e-05\nfractal_dimension_mean       -3.866346e-05 -6.902961e-05          -1.192792e-05\n\n\n\nqda_spec = discrim_quad() |>\n  set_mode('classification') |>\n  set_engine('MASS')\n\nqda_fit = wf |>\n  add_model(qda_spec) |>\n  fit(data = data_cancer_train)\n\n\nqda_metrics = qda_fit |> \n  fit_resamples(cross_folds,\n    metrics = metric_set(accuracy, roc_auc, sens, j_index, specificity),\n    control = control_resamples(save_pred = TRUE)) |>\n  collect_metrics() |>\n  mutate(lower_bound = mean - 1.96*std_err, upper_bound = mean + 1.96*std_err)"
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "3  Modelos de Classificação",
    "section": "",
    "text": "4 Modelos de Regressão e Apredendizado de Máquina"
  },
  {
    "objectID": "models.html#regressão-logística",
    "href": "models.html#regressão-logística",
    "title": "3  Modelos de Classificação",
    "section": "4.1 Regressão Logística",
    "text": "4.1 Regressão Logística\n\nlogistic_spec = parsnip::logistic_reg() |>\n  parsnip::set_engine(\"glm\", family = stats::binomial(link='logit')) |>\n  parsnip::set_mode(\"classification\")\n\n\nfitted_lr_model = wf |>\n  workflows::add_model(logistic_spec) |>\n  parsnip::fit(data_cancer_train) \n\ndoParallel::registerDoParallel()\nctrl_preds = control_resamples(save_pred = TRUE)\nrs_basic = fit_resamples(fitted_lr_model, cross_folds, control = ctrl_preds)\n\nrs_basic |> collect_metrics()\n\n# A tibble: 2 x 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.936    10 0.0116  Preprocessor1_Model1\n2 roc_auc  binary     0.985    10 0.00572 Preprocessor1_Model1\n\n\n\naugment(rs_basic) %>%\n  roc_curve(diagnosis, .pred_B) %>%\n  autoplot()"
  },
  {
    "objectID": "models.html#randon-forest",
    "href": "models.html#randon-forest",
    "title": "3  Modelos de Classificação",
    "section": "4.2 Randon Forest",
    "text": "4.2 Randon Forest"
  },
  {
    "objectID": "models.html#knn",
    "href": "models.html#knn",
    "title": "3  Modelos de Classificação",
    "section": "4.3 KNN",
    "text": "4.3 KNN"
  },
  {
    "objectID": "models.html#conclusão",
    "href": "models.html#conclusão",
    "title": "3  Modelos de Classificação",
    "section": "3.2 Conclusão",
    "text": "3.2 Conclusão\nObservando as estimativas obtidas via, viu-se que ambos os modelos apresentaram desempenho semelhantes. Assim utilizou-se como critério principal aquele que obteve o melhor desempenho na métrica sensibilidade dado que o contexto do problema trabalho indica um maior custo de erro para Falso Negativo\nPara melhor visualização, construi-se a seguinte tabela comparando o valor da sensibilidade de ambos os modelos:\n\nbind_rows(lda_metrics, qda_metrics) |>\n  filter(.metric == 'sens') |>\n  dplyr::select(-.config, -.estimator) |>\n  mutate(model = c('LDA', 'QDA')) |>\n  relocate(model)\n\n# A tibble: 2 x 7\n  model .metric  mean     n std_err lower_bound upper_bound\n  <chr> <chr>   <dbl> <int>   <dbl>       <dbl>       <dbl>\n1 LDA   sens    0.975    10 0.0107        0.954       0.996\n2 QDA   sens    0.972    10 0.00890       0.954       0.989\n\n\nNovamente, ambos os modelos se mostraram extramamentes semelhantes, porém notou-se um ligeiro melhor desempenho por parte do modelo Linear. Assim, seguiremso com ele para a etapa de final de escolha de melhor modelo"
  },
  {
    "objectID": "models.html#escolha-do-melhor-discriminante",
    "href": "models.html#escolha-do-melhor-discriminante",
    "title": "3  Modelos de Classificação",
    "section": "3.2 Escolha do Melhor Discriminante",
    "text": "3.2 Escolha do Melhor Discriminante\nObservando as estimativas obtidas via, viu-se que ambos os modelos apresentaram desempenho semelhantes. Assim utilizou-se como critério principal aquele que obteve o melhor desempenho na métrica sensibilidade dado que o contexto do problema trabalho indica um maior custo de erro para Falso Negativo\nPara melhor visualização, construi-se a seguinte tabela comparando o valor da sensibilidade de ambos os modelos:\n\nbind_rows(lda_metrics, qda_metrics) |>\n  filter(.metric == 'sens') |>\n  dplyr::select(-.config, -.estimator) |>\n  mutate(model = c('LDA', 'QDA')) |>\n  relocate(model) |>\n  kableExtra::kbl() %>%\n  kableExtra::kable_material(c(\"striped\", \"hover\"))\n\n\n\n \n  \n    model \n    .metric \n    mean \n    n \n    std_err \n    lower_bound \n    upper_bound \n  \n \n\n  \n    LDA \n    sens \n    0.9750000 \n    10 \n    0.0107143 \n    0.9540000 \n    0.9960000 \n  \n  \n    QDA \n    sens \n    0.9715517 \n    10 \n    0.0088986 \n    0.9541105 \n    0.9889929 \n  \n\n\n\n\n\nNovamente, ambos os modelos se mostraram extramamentes semelhantes, porém notou-se um ligeiro melhor desempenho por parte do modelo Linear. Assim, seguiremso com ele para a etapa de final de escolha de melhor modelo"
  }
]