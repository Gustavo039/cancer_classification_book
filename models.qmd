--- 
toc-title: Conteúdo
---

# Modelos de Classificação 

```{r, echo=F}
data_cancer = readr::read_csv('./data/data.csv') |>
  dplyr::mutate(diagnosis = as.factor(diagnosis)) |>
  dplyr::select(id, diagnosis , dplyr::contains('_mean')) |>
  dplyr::select(-perimeter_mean, -radius_mean) |>
  janitor::clean_names()

set.seed(607) #Fixando semente para reprodução dos resultados 
data_cancer_split = rsample::initial_split(data_cancer, prop = 0.80, strata = diagnosis)
data_cancer_train = rsample::training(data_cancer_split)
data_cancer_test = rsample::testing(data_cancer_split)

```

A classificação correta de tumores benignos e malignos desempenha um papel crucial no diagnóstico precoce e tratamento eficaz do câncer. Nesse contexto, os modelos de classificação surgem como ferramentas promissoras na área médica, permitindo a análise automatizada de características clínicas, genéticas e radiológicas para diferenciar entre tumores benignos e malignos. Esses modelos utilizam algoritmos de aprendizado de máquina para extrair padrões relevantes dos dados e fazer previsões precisas. Ao fornecer informações valiosas para médicos e especialistas, os modelos de classificação podem auxiliar na identificação de pacientes em risco, direcionar tratamentos personalizados e melhorar os resultados clínicos. Neste trabalho, exploraremos diferentes abordagens de modelos de classificação e discutiremos sua aplicação na discriminação entre tumores benignos e malignos, com o objetivo de aprimorar a detecção precoce e o tratamento eficiente do câncer.

A documentação dos dados cita que tal classificação indica o proseguindo ou não do paciente para exames mais invasivos, tal sequencia é ilustrada pelo seguinte diagrama:

![](figs/diag_fp_fn_falso.png){height=500px, fig-align="center"}

Porém, assim como todos modelos estatísticos, os modelos de classificação apresentam erros, tais erros de classificação são denominados **Falso Positivo** e **Falso Negativo**, onde no caso dos dados trabalhados:

* Falso Positivo: Falsa classificação de um paciente sem tumor maligno como portador de tal tumor

* Falso Negativo: Falsa classificação de um paciente com tumor maligno como não sendo portador de tal tumor

Tal definição é importante para a definição de limites e custos de erros.

O custo de erro associado ao erro **Falso Negativo** é maior que o **Falso Positivo** pois indica que um paciente com tumor maligno não deverá avancar em seu tratamento, podendo levar o mesmo a um estágio mortal da doença. Já a classificação Falso Positivo indica que o paciente sem tumor maligno avançe na diagnóstico da doença, onde serão utilizados metodos mais invasivos para isso

Portanto, o diagrama real é dada por:

![](figs/diag_fp_fn.png){height=500px, fig-align="center"}



```{r, message = F, warning=F}
library(tidymodels)
library(tidyverse)

variables_to_remove = data_cancer |>
  dplyr::select(contains("_mean")) |>
  names()

cancer_recipe = recipes::recipe(diagnosis ~ .,
                                data = data_cancer_train) |>
      recipes::update_role(id, new_role = "id") |>
      step_normalize(all_predictors()) |>
      step_mutate(anomaly_features = (area_mean + concave_points_mean + concavity_mean + texture_mean)/4,
                  structure_feature = (compactness_mean + fractal_dimension_mean + smoothness_mean + symmetry_mean)/4) |>
  update_role(all_of(variables_to_remove), new_role = "ignore")

wf = workflows::workflow() |> 
  workflows::add_recipe(cancer_recipe)


```


## Análise de Discriminante

O objetivo da análise discriminante é encontrar uma função discriminante que maximize a separação entre os grupos, levando em consideração a estrutura das variáveis preditoras.

Dado o contexto do problema estudado, a função discriminante estimada foi aquela que maximizou a separação entre os grupos de pessoas  com tumor benigno e maligno.

### Análise via Discriminante Linear

O discriminante linear é o mais simples dentre os modelos discriminantes. Ele busca separar os grupos de analises via uma reta, maximizando a distancia entre os grupos

```{r, warning=F, message=F}
library(discrim)

data_cancer_train = cancer_recipe |> prep() |> bake(new_data = NULL)
data_cancer_test = cancer_recipe |> prep() |> bake(new_data = data_cancer_test)

cross_folds = rsample::vfold_cv(data_cancer_train, strata = diagnosis)
```

Para uma estimação robusta, utilizou-se o método de **cross validation**, que se trata da divisão do conjunto de treino em determinado número de *folds*, no caso foram dividos 10 folds. A cada iteração 9 folds eram usados como fonte de dados para otimização dos parametros do modelo e o fold restante era utilizado como validação das métricas. Ao final, obteu-se as seguintes metricas


Para cada metrica, foi construido um intervalo de confiança de $95\%$

```{r}
lda_spec = discrim_linear() |>
  set_mode('classification') |>
  set_engine('MASS')

lda_fit = wf |>
  workflows:: add_model(lda_spec) |>
parsnip::fit(data = data_cancer_train)
  
```

```{r}
library(tidyverse)
library(tidymodels)

lda_metrics = lda_fit |> 
  tune::fit_resamples(cross_folds,
    metrics = yardstick::metric_set(accuracy, roc_auc, sens, j_index, specificity),
    control = tune::control_resamples(save_pred = TRUE)) |>
  workflowsets::collect_metrics() |>
  mutate(lower_bound = mean - 1.96*std_err, upper_bound = mean + 1.96*std_err) 

lda_metrics|>
  kableExtra::kbl() %>%
  kableExtra::kable_material(c("striped", "hover"))
```



### Análise via Discriminante Quadrático

O modelo de discrimante quadrático é mais utilizado quando as matrizes de covariancias são diferentes entre os grupo.

```{r}
qda_spec = discrim_quad() |>
  set_mode('classification') |>
  set_engine('MASS')

qda_fit = wf |>
  add_model(qda_spec) |>
  fit(data = data_cancer_train)
```

Para uma estimação robusta, utilizou-se novamente o método de **cross validation**

```{r}
qda_fitted_resamples = qda_fit |> 
  fit_resamples(cross_folds,
    metrics = metric_set(accuracy, roc_auc, sens, j_index, specificity),
    control = control_resamples(save_pred = TRUE))

qda_metrics =  qda_fitted_resamples |>
  collect_metrics() |>
  mutate(lower_bound = mean - 1.96*std_err, upper_bound = mean + 1.96*std_err)

qda_metrics |> 
  kableExtra::kbl() %>%
  kableExtra::kable_material(c("striped", "hover"))
```


## Escolha do Melhor Discriminante

Observando as estimativas obtidas, viu-se que ambos os modelos apresentaram desempenho semelhantes. Assim utilizou-se como critério principal aquele que obteve o melhor desempenho na métrica **sensibilidade** dado que o contexto do problema trabalho indica um maior custo de erro para **Falso Negativo**

Para melhor visualização, construi-se a seguinte tabela comparando o valor da sensibilidade de ambos os modelos:

```{r}
bind_rows(lda_metrics, qda_metrics) |>
  filter(.metric == 'sens') |>
  dplyr::select(-.config, -.estimator) |>
  mutate(model = c('LDA', 'QDA')) |>
  relocate(model) |>
  kableExtra::kbl() %>%
  kableExtra::kable_material(c("striped", "hover"))
  
```

Novamente, ambos os modelos se mostraram extramamentes semelhantes, porém notou-se um ligeiro melhor desempenho por parte do modelo Linear. Assim, escolheu-se ele para a etapa de final de escolha de melhor modelo

# Modelos de Regressão e Apredendizado de Máquina

## Regressão Logística

A regressão logística é um modelo estatístico utilizado para prever a probabilidade de ocorrência de um evento binário

No contexto do problema trabalhado, utilizou-se a função de ligação **logito**

```{r}
logistic_spec = parsnip::logistic_reg() |>
  parsnip::set_engine("glm", family = stats::binomial(link='logit')) |>
  parsnip::set_mode("classification")
```


Para uma estimação robusta, utilizou-se novamente o método de **cross validation**

```{r}
lr_fit = wf |>
  workflows::add_model(logistic_spec) |>
  parsnip::fit(data_cancer_train) 


lr_fitted_resamples = lr_fit |>
  fit_resamples(cross_folds,
    metrics = metric_set(accuracy, roc_auc, sens, j_index, specificity),
    control = control_resamples(save_pred = TRUE))

lr_metrics = lr_fitted_resamples |> 
  collect_metrics() |>
  mutate(lower_bound = mean - 1.96*std_err, upper_bound = mean + 1.96*std_err)

lr_metrics|>
  kableExtra::kbl() %>%
  kableExtra::kable_material(c("striped", "hover"))

```

O modelo de Regressão Logistica apresentou um desempenho semelhante ao de discriminates, uma análise mais detalaha foi feito nos próximos tópicos


## Randon Forest

Random Forest é um algoritmo de aprendizado de máquina baseado em árvores de decisão. Ele combina várias árvores para criar um modelo robusto e preciso. Cada árvore é treinada em uma amostra aleatória e faz previsões independentes, e o resultado final é obtido por votação ou média. É eficaz em problemas de classificação e regressão, lidando com sobreajuste e identificando características importantes.

No contexto do problema trabalhado, a random forest foi definida para classificação.

Além disso, foi utilizado o metodo de otimização de parâmetros para a construção de um melhor modelo

```{r, message=F, warning=F}
library(randomForest)

rand_forest_spec = rand_forest(
  mtry = tune(),
  trees = 2000,
  min_n = tune()
) %>%
  set_mode("classification") %>%
  set_engine("randomForest")
```

```{r}
rand_forest_fit = wf |>
  workflows::add_model(rand_forest_spec) 

doParallel::registerDoParallel()

rand_forest_tune = rand_forest_fit |>
  tune_grid(
    resamples = cross_folds,
    metrics = metric_set(accuracy, roc_auc, sens, j_index, specificity),
    grid = 10)

rand_forest_tune |>
  collect_metrics() %>%
  filter(.metric == 'sens') %>%
  dplyr::select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "sens")


rand_forest_tune |>
  collect_metrics() %>%
  filter(.metric == 'roc_auc') %>%
  dplyr::select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")

```

Observando os valores dos hiperparametros  *min_n* e *mtry* vemos um intervalo definido em que eles apresentaram melhor desempenho para a otimização da area sob a curve ROC e para a sensibilidade do modelo

Assim, foi realziado um estudo maior sobre esse área de otimização


```{r}
doParallel::registerDoParallel()
 grid_table = crossing(min_n = seq(10,11, by=.1),
          mtry = c(0,1, by = 0.1))

rand_forest_tune = rand_forest_fit |>
  tune_grid(
    resamples = cross_folds,
    metrics = metric_set(accuracy, roc_auc, sens, j_index, specificity),
    grid = grid_table)
```


Assim, os parametros ótimos são:

* **min_n** = 10.3

* **mtry** = 0.1

```{r}
rand_forest_spec = rand_forest(
  mtry = 0.1,
  trees = 2000,
  min_n = 10.3
) %>%
  set_mode("classification") %>%
  set_engine("randomForest")

rand_forest_fit = wf |>
  workflows::add_model(rand_forest_spec) 

rand_forest_fitted_resamples = rand_forest_fit |>
  fit_resamples(
    resamples = cross_folds,
    metrics = metric_set(accuracy, roc_auc, sens, j_index, specificity)
    )

```

Para uma estimação robusta das metricas, utilizou-se novamente o método de **cross validation**

```{r}
rand_forest_fitted_resamples = rand_forest_fitted_resamples |> 
  collect_metrics() 

rand_forest_fitted_resamples |>
    mutate(lower_bound = mean - 1.96*std_err, upper_bound = mean + 1.96*std_err) |>
    kableExtra::kbl() %>%
    kableExtra::kable_material(c("striped", "hover"))
```

O modelo de Random Forest apresentou um desempenho semelhante aos demais modelos, uma análise mais detalhada foi feito nos próximos tópicos


# Escolha do Melhor modelo

Nesse tópico trabalhou-se com os 3 modelos construidos: **Discriminante Linear**, **Regressão Logística** e **Random Forest Otimizado**

Para a escolha do melhor modelo, utilizou-se principalmente as métricas **Curva ROC, Sensibilidade e J-Index**

* **Curva ROC**: Representa a área sob a curva ROC, quanto maior for essa área, mekhor foi o desempenho do modelo

* **Sensibilidade**: Indica a taxa de verdadeiros positivos do modelos, no contexto trabalhado, indica individuos com tumores malignos que foram classificados corretamente

* **J-Index**: Dado por = (sensibilidade+especificidade)-1, é uma metrica que busca resumir os valores de sensibilidade e especificidade em um valor só


Os modelos possuem as seguintes metricas(para robuste dos valores, foi utilizado novamente metodo de validação cruzada)

```{r}
bind_rows(lda_metrics, lr_metrics, rand_forest_fitted_resamples) |>
  mutate(lower_bound = mean - 1.96*std_err, upper_bound = mean + 1.96*std_err,
         model = c(rep('LDA', 5), rep('RegLog', 5), rep('RandFor',5))
         ) |>
  relocate(model) |>
  dplyr::select(-'.config') |>
  kableExtra::kbl() %>%
  kableExtra::kable_material(c("striped", "hover"))
```


Analisando os valores calculados, viu-se que os 3 modelos aprsentaram valores semelhantes para a area sob a curva ROC. Já para a sensibilidade, o modelo de discriminante linear foi aquele a apresentar melhor desempenho, possuindo uma estimativa pontual alta e um baixo valor de erro padrão. No entanto, o modelo LDA foi aquele a apresentar o pior valor de J-Index e portanto apresentou um baixo desempenho em balancear erros de falso positivo e falso negativo. O modelo a apresentar um bom desempenho nos 3 metricas foi o de regressão logistica.

Os modelos de Regressão Logistica e de Random Forest apresentarm desempenho semelhantes nas 3 métricas de interesse, porém, dado que o modelo logístico possui uma melhor interpretabilidade e um menor tempo de execução computacional ele foi o escolhido como o melhor modelo de classificação para o tema estudado

## Interpretação e Métricas do Modelo nos Dados de Teste

No início do tópico de exploração de dados, os dados foram dividos em treino em teste, onde toda a etapa de exploração e modelagem foi realizado em cima do conjunto de dados de treino.

O seguinte tópico busca observar o comportamento do modelo selecionado como o melhor entre os 3 construidos no conjunto de dados de treino. A divisão de dados ajuda a reduzir a viés amostral e ajuda a observar a capacidade de generalização do modelo em novos dados.

O modelo selecionado foi o de Regressão Logistica, que possui a seguinte forma:


$$ln(\frac{Y}{1-Y})=\beta_0 + \beta_1*anomaly\_feature + \beta_2*structure\_feature$$

Com os Betas estimados de:

$$\beta_0 = -19.00366, e \ ROR_{beta_0}=exp(-19.00366) = 5.5 *10^{-9}$$
$$\beta_1 = 85.72805, e \ ROR_{beta_1}=exp(85.72805) = 1.7 * 10^{35}$$

$$\beta_2 = -0.05412, e \ ROR_{beta_2}=exp(-0.05412) = 0.9472426$$


Interpretando os betas calculados para cada variável expliativa, temos que 

* Foi calculado um **Regression Odds Ratio** de $1.7 * 10^{35}$ para a variável anomalia celular, que possui metricas como área celular, concavidade e textura. Isso indica que quanto maior for o grau de anomalia celular do individuo, maior será a chance de se possuir um tumor maligno. Via **ROR**, para cada 1 unidade aumentada nessa variável, a probabilidade do individuo possuir um tumor maligno é $1.7 * 10^{35}$ da probabilidade de um individuo com uma unidade a menos

* Foi calculado um **Regression Odds Ratio** de $0.9472426$ para a variável estrutura celular, que possui metricas como dimensão fractal, suavidade e simetria celular. Isso indica que quanto maior for o grau qualidade da estrutura celular, menor será a chance do indivíduo possuir um tumor maligno. Via **ROR**, para cada 1 unidade aumentada nessa variável, a probabilidade do individuo possuir um tumor maligno é $0.9472426$ da probabilidade de um individuo com uma unidade a menos

Assim, os betas estimados são bem explicados pelo contexto do problema. Quanto maior o grau de anomalia celular, maior a chance de se possuir um tumor maligno, enquanto, quanto maior for a qualidade da estrutura celular, menor a chance de se possuir um tumor maligno

O modelo teve o seguinte desempenho no conjunto de dados de treino

* Matriz de confusão

```{r}
library(probably)
cancer_preds =
  augment(lr_fit, data_cancer_test) |>
  dplyr::select(diagnosis, contains("pred")) |>
  mutate(
      pred = make_two_class_pred(
      estimate = .pred_B, 
      levels = levels(diagnosis), 
      threshold = .65
    )
  ) 

cancer_preds |>
  conf_mat(diagnosis, pred) |>
  autoplot(type = 'heatmap') 
```

Com as seguintes métricas calculadas

```{r}
data.frame(sens = yardstick::sens(cancer_preds,
                       diagnosis,
                       pred),
          spec = yardstick::spec(cancer_preds,
                       diagnosis,
                       pred),
          j_index = yardstick::j_index(cancer_preds,
                       diagnosis,
                       pred)
           ) |>
  dplyr::select(contains("estimate"))|>
  kableExtra::kbl() %>%
  kableExtra::kable_material(c("striped", "hover"))
```

Portanto, a partir da matriz de confusão e das metricas calculadas, vemos um bom desempenho do modelo. Apresentando um baixo erro de falso negativo (alta sensibilidade) e uma boa especificidade. Os valores calculados nos dados de teste foram semelhantes a aqueles calculados nos dados de treino, indicando uma boa generalização do modelo.



