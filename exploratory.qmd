--- 
toc-title: Conteúdo
---

# Análise exploratória de Dados

O seguinte capítulo tem como objetivo realizar uma análise exploratória nos dados. Para isso iremos seguir o seguinte esquema:

![](figs/diag_explo.drawio.png){height=500px, fig-align="center"}


## Carregamento dos dados

Os dados utilizados nesse trabalho foram retirados do [**Kaggle**](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data?resource=download) e se tratam de valores estimados a partir de uma imagem digitalizada de um aspirado com agulha fina (PAAF) de uma massa mamária com tumor. Assim, os dados descrevem características dos núcleos celulares presentes nas imagens. 

Carregamento dos dados:

```{r, echo=FALSE}
data_cancer = readr::read_csv('./data/data.csv') |>
  dplyr::mutate(diagnosis = as.factor(diagnosis )) 

data_cancer |> dplyr::glimpse()
```

Nota-se que o conjunto de dados possui 568 observações com 33 variaveis



```{r}
data_cancer |> visdat::vis_miss()
```

A partir do gráfico de valores faltantes, nota-se que apenas uma coluna possui **NAs**, assim ela foi removida do conjunto de dados (variavel não apresentava nenhum valor e provalvelmente é resquício de um erro no upload dos dados por parte **UCI Machine Learning Repositor**)

```{r}
data_cancer = data_cancer|>
  dplyr::select(-'...33' )


data_cancer |> head()
```

As 5 primeiras linhas do conjunto de dados mostram que das 32 variáveis remanescentes, 30 são numericas, 1 categórica e a restante representa um ID do paciente analisado. **Os modelos desenvolvidos nesse trabalho buscam classificar o diagnóstico do paciente (tumor maligno ou benigno)** com base nas variáveis numéricas. Assim é importantíssima a análise de tais variáveis, estudando valores de correlação, aderência e significância

Um estudo de simulação, assim como a documentação dos dados indica que não há falta de informação ao se trabalhar com a colunas numericas **_mean**, assim 

```{r}
data_cancer = data_cancer |>
  dplyr::select(id, diagnosis , dplyr::contains('_mean'))
```

Para o estudo, há a necessidade de verificação de desbalanceamento do conjunto de dados. Tal verificcação foi feita em cima de análise gráfica, de proporções de cada grupo

```{r}
prop_df = data_cancer |>
  dplyr::reframe(prop_B = mean(diagnosis == 'B'), prop_M = mean(diagnosis == 'M')) |>
  tidyr::pivot_longer(c(prop_B, prop_M))

data_cancer |> 
  ggplot2::ggplot(ggplot2::aes(x = diagnosis, fill = diagnosis)) +
  ggplot2::geom_bar() +
  ggplot2::theme_minimal() +
  ggthemes::scale_fill_colorblind()
```

Alem da visualização gráfica, foi utilizado o **Coeficiente de Entropia de Shannon**, que vai de 0 a 1, onde 0 indica dados totalmente desbalanceados (proporção $0\%$ e $100\%$) e 1 balanceamento completo (proporção $50\%$ e $50\%$)

```{r}
DescTools::Entropy(data_cancer$diagnosis |> table())
```

O Coeficiente calculado foi de: $0.953127$

Assim, a partir do grafico de barras, proporções de cada grupo e teste de Entropia de Shannon, não há evidencias para um desbalanceadmento significativo no conjunto de dados utilizados

O próximo tópico busca tal objetivo .Antes porém,  buscando diminuir o vies amostral, o conjunto de dados será divido em treino e teste, com proporção $80\% \ e \ 20\%$ @, o metodo de divisão utilizado será de amostragem estratificada simples, tal método foi escolhido para evitar desbalanceamento de diagnosticos malignos e benignos nos conjuntos de treino e teste. Portanto, toda a análise e modelagem realizada nos próximos topicos foi em cima do conjunto de dados de teste, ao final da etapa de modelagem foi realizado o ultimo ajuste dos modelos, onde é utilizado o conjunto total dos dados



```{r}
set.seed(607) #Fixando semente para reprodução dos resultados 
data_cancer_split = rsample::initial_split(data_cancer, prop = 0.80, strata = diagnosis)
data_cancer_train = rsample::training(data_cancer_split)
data_cancer_test = rsample::testing(data_cancer_split)
```



## Análise e interpretação das variaveis

```{r}
hist_vars_cancer = apply(data_cancer_train[,3:12], 2, 
      function(vars_){
          data_cancer_train |>
          ggplot2::ggplot(ggplot2::aes(x = vars_, color = diagnosis)) +
          ggplot2::geom_histogram(ggplot2::aes(y = ggplot2::after_stat(density))) +
          ggthemes::scale_colour_colorblind()

})

do.call(gridExtra::grid.arrange, hist_vars_cancer)
```

Teste de aderencia de distribuições para variaveis dividias por grupo:

```{r}
B = data_cancer_train |>
      dplyr::filter(diagnosis == 'B') 

M = data_cancer_train |>
      dplyr::filter(diagnosis == 'M') 

grip_test = sapply(3:12, function(i){
  dist1 = B[,i] |> dplyr::pull()
  dist2 = M[,i] |> dplyr::pull()
  ks = ks.test(dist1, dist2)
  cr = cramer::cramer.test(dist1, dist2)
  
  return(c(ks$p.value, cr$p.value))
})
```




## Redução de dimensionalidade 

Dados do mundo real, como sinais de fala, fotografias digitais ou varreduras de fMRI, geralmente têm alta dimensionalidade. Para lidar adequadamente com os dados do mundo real, dimensionalidade precisa ser reduzida. Redução de dimensionalidade é a transformação de dados de alta dimensão em uma representação significativa de dimensionalidade reduzida. Idealmente, a representação reduzida deve ter uma dimensionalidade que corresponde à dimensionalidade intrínseca dos dados [@van2009dimensionality]



### Análise de Componentes Principais

Análise de Componentes Principais (PCA) constroi uma representação de baixa dimensão dos dados que descreve o máximo possível da variância dos dados.
 
A técnica se baseia no cálculo de autovalores e autovetores, buscando assim associção lineares entre as variáveis. 

```{r}
pr_cancer = data_cancer_train |>
  dplyr::select(dplyr::contains('_mean')) |> 
  princomp() 
```

```{r}
pr_cancer |> factoextra::fviz_eig()
```

Observando o gráfico da variabilidade captada por cada componente, viu-se que a primeira dimensão captou grande parte dessa variabilidade e assim, trabalhou-se apenas com uma dimensão na análise dos dados via **PCA**

Buscando visualizar quanto cada variável contribui na primeira componente construiu-se o seguinte gráfico

```{r}
pr_cancer |> factoextra::fviz_contrib(choice = "var", axes = c(1))
```

Viu-se que a variável **area-mean** foi predominante na primeira componente. As demais variáveis não foram captadas significativamente pela primeira componente, porém, ao se rankear elas, observou-se que uma maior importância daquelas variáveis correspondentes ao questões de tamanho celulares, como: **area-mean, perimeter_mean, radius_mean**

Além disso, tais variáveis são altamente linearmente dependentes, onde tanto area como perímetro são função do raio.

Onde tem-se os seguintes valores de correlação:

```{r}
data_cancer_train |> 
  dplyr::select(area_mean, perimeter_mean, radius_mean) |> 
  cor() |>
  ggcorrplot::ggcorrplot(hc.order = TRUE, 
                         type = "lower",
                         lab = TRUE,
                         colors = c("#6D9EC1", "white", "#E46726"))
```


Assim, buscando eliminar multicolinearidade dos dados, eliminou-se as variáveis: **perimeter_mean, radius_mean**.

```{r}
data_cancer_train = data_cancer_train |>
  dplyr::select(-perimeter_mean, -radius_mean)
```


Realizando novamente a redução de dimensionalidade, mas agora sem as variáveis **perimeter_mean, radius_mean**, tem-se:

```{r}
pr_cancer = data_cancer_train |>
  dplyr::select(dplyr::contains('_mean')) |> 
  princomp() 

pr_cancer |> factoextra::fviz_eig()

pr_cancer |> factoextra::fviz_contrib(choice = "var", axes = c(1))
```


```{r}
pr_cancer |> factoextra::fviz_pca_var(col.var = "black")
```

```{r}
factoextra::fviz_pca_ind(pr_cancer,
             label = "none", # hide individual labels
             habillage = data_cancer_train$diagnosis, # color by groups
             palette = c('black', 'yellow'),
             addEllipses = TRUE # Concentration ellipses
             )
```



### Análise Fatorial

```{r}
fa_ml_cancer = data_cancer_train |>
                dplyr::select(dplyr::contains('_mean')) |>
  psych::fa(nfactors = 2, rotate = 'varimax', fm = 'ml') 

fa_ml_cancer |> psych::fa.diagram()
fa_ml_cancer$scores |>
  as.data.frame() |>
  dplyr::mutate(diagnosis = data_cancer_train$diagnosis) |>
  ggplot2::ggplot(ggplot2::aes(ML1, ML2, col = diagnosis)) +
  ggplot2::geom_point(size = 2) +
  ggplot2::labs(title = 'Redução via Verossimilhança') +
  ggthemes::scale_colour_colorblind()
```



